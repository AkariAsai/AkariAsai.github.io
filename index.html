<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Akari Asai </title> <meta name="author" content="Akari Asai"> <meta name="description" content="A research scientist at Allen Institute for AI and an incoming assistant professor at CMU, focusing on natural language processing, machine learning, and large language models. "> <meta name="keywords" content="NLP, ML, LLM"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?16404ec2cd2689e8d0f38f73fe0d38f9"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%95&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://akariasai.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%61%6B%61%72%69@%63%73.%77%61%73%68%69%6E%67%74%6F%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=gqB4u_wAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/35584853" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/AkariAsai" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/AkariAsai" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/award/">Awards </a> </li> <li class="nav-item "> <a class="nav-link" href="/press/">Press &amp; Talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">Service </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/akariasai_cv.pdf">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/groups/">Joining us </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Akari</span> Asai </h1> <p class="desc">Research Scientist @ <a href="https://allenai.org/" rel="external nofollow noopener" target="_blank">Allen Institute for AI</a><br>Incoming Assistant Professor @ <a href="https://www.cs.cmu.edu/" rel="external nofollow noopener" target="_blank">Carnegie Mellon University</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 1000px) 291.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?65c49e9a72dc27aab16953ebf44b94c0" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am an incoming Assistant Professor at Carnegie Mellon University (Fall 2026-) <a href="https://www.lti.cs.cmu.edu/" rel="external nofollow noopener" target="_blank">Language Technologies Institute</a>, with an affiliate appointment in <a href="https://ml.cmu.edu/" rel="external nofollow noopener" target="_blank">the Machine Learning Department</a> and a research scientist at <a href="https://allenai.org/" rel="external nofollow noopener" target="_blank">OLMo @ the Allen Institute for AI</a> (2025-2026).</p> <p><strong>I am hiring 2-3 Ph.D. students at CMU in the 2025-2026 application cycle. Please check out <a href="https://akariasai.github.io/groups/">FAQ</a> for more info.</strong></p> <p>I’ve completed my Ph.D. in NLP at Paul G. Allen School of Computer Science &amp; Engineering, University of Washington. I am fortunate to be advised by <a href="https://homes.cs.washington.edu/~hannaneh/index.html" rel="external nofollow noopener" target="_blank">Prof. Hannaneh Hajishirzi</a>. I was also spending time at <a href="https://ai.meta.com/research/" rel="external nofollow noopener" target="_blank">Meta AI Research</a> as a visiting student researcher, under the supervision of <a href="https://scottyih.org/" rel="external nofollow noopener" target="_blank">Dr. Wen-tau Yih</a>. My Ph.D. pioneered <a href="https://acl2023-retrieval-lm.github.io/" rel="external nofollow noopener" target="_blank"><strong>Retrieval-Augmented LMs</strong></a>, LMs that integrate large-scale text data via retrieval during inference (<a href="assets/pdf/akari_phd_dissertation.pdf">thesis (PDF)</a>, <a href="https://www.youtube.com/watch?v=qnWyU9zryao" rel="external nofollow noopener" target="_blank">video (youtube)</a>.)</p> <p>Prior to joining UW, I obtained a B.E. in <a href="https://www.ee.t.u-tokyo.ac.jp/en/" rel="external nofollow noopener" target="_blank">Electrical Engineering and Computer Science</a> from The University of Tokyo, Japan.</p> <p><strong>Current Research Focus:</strong> My research focuses on natural language processing and machine learning, with a particular emphasis on large language models (LLMs). I’m interested in building LMs and agents that are more reliable, modular, and open, aimed at real-world impact in science, code, and global information access.</p> <ul> <li> <p><strong>Developing Augmented LMs</strong>: We design, train, and deploy augmented LMs and agents that collaborate with complementary modules—retrieval, tool use, multi-LM coordination, and more—moving beyond the limits of scaling a single monothilic model and introduce new training and inference algorithms for those methods. Recent work includes advanced retrieval-augmented LMs such as <a href="https://arxiv.org/abs/2310.11511" rel="external nofollow noopener" target="_blank">Self-RAG</a>, and <a href="http://allenai-web/papers/drtulu" rel="external nofollow noopener" target="_blank">DR Tulu</a>, the first end-to-end open deep research agent for open-ended, long-form tasks trained with reinforcement learning with evolving rubrics. We also tackle system-level challenges for scalability and efficiency (e.g., <a href="https://arxiv.org/abs/2407.12854" rel="external nofollow noopener" target="_blank">MassiveDS</a>, <a href="https://arxiv.org/abs/2106.00882" rel="external nofollow noopener" target="_blank">BPR</a>) and extend these capabilities to multimodal settings (<a href="https://arxiv.org/abs/2410.16153" rel="external nofollow noopener" target="_blank">Pangea</a>, <a href="https://neurips.cc/virtual/2025/loc/san-diego/competition/127730" rel="external nofollow noopener" target="_blank">MM-RAG NeurIPS Competition</a>).</p> </li> <li> <p><strong>Understanding and Mitigating Failure Modes of LMs</strong>: We systematically investigate where and why LMs fail, including hallucinations, copyright infringements, and unreliable reasoning, and design mechanisms to improve their reliability and safety. Projects such as <a href="https://arxiv.org/abs/2212.10511" rel="external nofollow noopener" target="_blank">When Not to Trust LMs</a>, copyright–utility trade-offs of LMs in <a href="https://arxiv.org/abs/2407.07087" rel="external nofollow noopener" target="_blank">CopyBench</a>, and analyses of capability–hallucination trade-offs in <a href="https://arxiv.org/abs/2510.17733" rel="external nofollow noopener" target="_blank">Binary RAR</a> exemplify our efforts to make LMs more trustworthy and robust.</p> </li> <li> <p><strong>Deploying Augmented LMs in High-Impact Domains</strong>: We apply our methods to real-world challenges that demand factuality, transparency, and accessibility. Examples include AI for science (<a href="https://arxiv.org/abs/2411.14199" rel="external nofollow noopener" target="_blank">OpenScholar</a>, used by tens of thousands of scientists for literature synthesis), AI for code <a href="https://arxiv.org/abs/2406.14497" rel="external nofollow noopener" target="_blank">CodeRAGBench</a>, and AI for linguistic equity (<a href="https://arxiv.org/abs/2010.11856" rel="external nofollow noopener" target="_blank">XORQA</a>, <a href="https://arxiv.org/abs/2305.06897" rel="external nofollow noopener" target="_blank">AfriQA</a>, <a href="https://arxiv.org/abs/2107.11976" rel="external nofollow noopener" target="_blank">CORA</a>), broadening global access to reliable information.</p> </li> </ul> <p>Selected recognitions include <a href="https://www.technologyreview.com/innovators-under-35/2025/" rel="external nofollow noopener" target="_blank">MIT Technology Review 35 Innovators Under 35</a> (2025 Global &amp; 2024 Japan), <a href="https://www.forbes.com/30-under-30/2025/asia/healthcare-science" rel="external nofollow noopener" target="_blank">Forbes 30 Under 30 Asia in Science 2025</a>, <a href="https://risingstars.utexas.edu/profiles/akari-asai" rel="external nofollow noopener" target="_blank">EECS Rising Stars 2022</a>, and the <a href="https://news.cs.washington.edu/2022/10/20/lost-in-translation-no-more-ibm-fellowship-winner-akari-asai-asks-and-answers-big-questions-in-nlp-to-expand-information-access-to-all/" rel="external nofollow noopener" target="_blank">IBM Global Ph.D. Fellows 2022-202</a>. Our work has been covered by <a href="https://www.forbes.com/councils/forbestechcouncil/2024/07/30/how-rag-powered-ai-applications-have-a-positive-impact-on-businesses/" rel="external nofollow noopener" target="_blank">Forbes</a>, <a href="https://www.nature.com/articles/d41586-025-02853-8" rel="external nofollow noopener" target="_blank">Nature News</a>, and <a href="https://www.technologyreview.com/2018/02/05/145813/100000-happy-moments/" rel="external nofollow noopener" target="_blank">MIT Technology Review</a>, and is used in libraries such as <a href="https://huggingface.co/docs/transformers/en/model_doc/luke" rel="external nofollow noopener" target="_blank">Hugging Face</a>, <a href="https://docs.llamaindex.ai/en/stable/api_reference/packs/self_rag/" rel="external nofollow noopener" target="_blank">LlamaIndex</a>, and <a href="https://blog.langchain.dev/agentic-rag-with-langgraph/" rel="external nofollow noopener" target="_blank">LangChain</a>. Most recently, the <a href="https://openscholar.allen.ai/" rel="external nofollow noopener" target="_blank">Ai2 OpenScholar Public Demo</a> has supported 50k researchers across scientific disciplines in synthesizing literature.</p> <p><strong>Public office hours and application materials:</strong> To help lower barriers to starting research, pursuing a Ph.D. in this field or job search, I host weekly office hours open to all every Friday. Feel free to sign up via (please sign up from <a href="https://calendar.app.google/3daW5UMPCNc7qJdQA" rel="external nofollow noopener" target="_blank">Google Calendar</a>!).</p> <p>Inspired by many wonderful friends who have shared their own materials to promote equity and access, I’ve also made my past application materials available:</p> <ul> <li>Academic job application (2024): <a href="assets/pdf/akariasai_2024_research.pdf">[Research Statement]</a>, <a href="assets/pdf/akariasai_2024_teaching.pdf">[Teaching Statement]</a>, <a href="assets/pdf/akariasai_2024_dei.pdf">[Diversity Statement]</a>, <a href="assets/pdf/akari_job_talk_slides.pdf">[Job Talk Slides]</a>, <a href="https://www.youtube.com/watch?v=qnWyU9zryao" rel="external nofollow noopener" target="_blank">[Job Talk Video (defense recording)]</a> </li> <li>EECS Rising Stars (2022): <a href="assets/pdf/akari_eecs_rising_stars.pdf">[Research Statement]</a> </li> <li>PhD application (2018): <a href="assets/pdf/akari_Sop_UW_Draft.pdf">[SoP draft]</a> (<em>Note: This is a near-final draft, as I don’t have access to the original version anymore! For examples of CS Statements of Purpose, I recommend checking out <a href="https://cs-sop.notion.site/" rel="external nofollow noopener" target="_blank">cs-sop</a>, which includes many CS SoP of previous applicants!</em>)</li> </ul> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 20, 2025</th> <td> <a href="https://allenai.org/blog/olmo3" rel="external nofollow noopener" target="_blank"><strong>OLMo</strong></a> 3 is out! New 7B &amp; 32B models rival Qwen3 while being fully open. Check out <a href="http://allenai.org/papers/olmo3" rel="external nofollow noopener" target="_blank">the tech report</a> for many interesting findings and try OLMo on <a href="https://playground.allenai.org/" rel="external nofollow noopener" target="_blank">Ai2 playground</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 19, 2025</th> <td> Super excited to share <a href="https://allenai.org/blog/dr-tulu" rel="external nofollow noopener" target="_blank"><strong>DR Tulu</strong></a> - an open, end-to-end trained deep research agent for long-form, real-world research tasks. We introduce a new RL recipe, <strong>Reinforcement Learning with Evolving Rubrics (RLER)</strong>, to tackle the inherently hard-to-verify nature of deep research. Check out <a href="https://allenai.org/papers/drtulu" rel="external nofollow noopener" target="_blank">our paper</a> and <a href="https://dr-tulu.github.io/" rel="external nofollow noopener" target="_blank">a static demo</a>. A live demo is coming soon so please stay tuned! </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 02, 2025</th> <td> I spoke with the <a href="https://youtu.be/nroNb-Fgcgs?si=Y_EDmPrGl6a3vHsB" rel="external nofollow noopener" target="_blank">Delta Institue Podcast</a> about my path to CS/NLP, recent progress in augmented LMs &amp; agents, and remaining challenges. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 30, 2025</th> <td> I gave an invited lecture on retrieval and retrieval-augmented LMs at CMU Advanced NLP and LLMs! <a href="assets/pdf/akari_anlp_2025_rag_lecture.pdf">Slide</a> and <a href="https://www.youtube.com/watch?v=6PMEqN0-gkM" rel="external nofollow noopener" target="_blank">Lecture video</a> are publicly available. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 09, 2025</th> <td> <a href="https://arxiv.org/abs/2411.14199" rel="external nofollow noopener" target="_blank">OpenScholar</a> has been highlighted in <a href="https://www.nature.com/articles/d41586-025-02853-8" rel="external nofollow noopener" target="_blank">Nature News - “Can researchers stop AI making up citations?”</a>. </td> </tr> </table> </div> </div> <h2> <a href="/blog/" style="color: inherit">latest posts</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 25, 2025</th> <td> <a class="news-title" href="/2025/11/25/job-search.html">Note from my 2024-2025 academic job search</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <p>See my full publications at <a href="https://akariasai.github.io/publications/">the publication page</a>!</p> <ol class="bibliography"> <li> <div class="row"> <div id="olmo2025" class="col-sm-11"> <div class="title">DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research</div> <div class="author"> OlmoTeam </div> <div class="periodical"> 2025 </div> <div class="periodical"> Preprint </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://allenai.org/papers/olmo3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/allenai/OLMo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://allenai.org/blog/olmo3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>We introduce Olmo3,a family of state-of-the-art, fully open language models at the 7B and 32B parameter scales.Olmo3 model construction targets long context reasoning, function calling,coding, instruction following, general chat, and knowledge recall. The release includes the entire model flow, i.e.,the full life cycle of the family of models, including every stage,checkpoint,datapoint,and dependency used to build it. Our flagship model, Olmo3 Think-32B, is the strongest fully open thinking model released to-date.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="shao2025drtulu" class="col-sm-11"> <div class="title">DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research</div> <div class="author"> Rulin Shao* ,  <em>Akari Asai*</em> ,  Shannon Zejiang Shen* ,  Hamish Ivison* ,  Varsha Kishore , and <span class="more-authors" title="click to view 16 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '16 more authors' ? 'Jingming Zhuo, Xinran Zhao, Molly Park, Samuel Finlayson, David Sontag, Tyler Murray, Sewon Min, Pradeep Dasigi, Luca Soldaini, Faeze Brahman, Wen-tau Yih, Tongshuang Wu, Luke Zettlemoyer, Yoon Kim, Hannaneh Hajishirzi, Pang Wei Koh' : '16 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">16 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> Preprint </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2511.19399" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/rlresearch/DR-Tulu" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://allenai.org/blog/dr-tulu" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="asai2024openscholar" class="col-sm-11"> <div class="title">OpenScholar: Synthesizing Scientific Literature with Retrieval-Augmented LMs</div> <div class="author"> <em>Akari Asai</em> ,  Jacqueline He ,  Rulin Shao ,  Weijia Shi ,  Amanpreet Singh , and <span class="more-authors" title="click to view 20 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '20 more authors' ? 'Joseph Chee Chang, Kyle Lo, Luca Soldaini, Sergey Feldman, D’arcy Mike, David Wadden, Matt Latzke, Minyang, Pan Ji, Shengyan Liu, Hao Tong, Bohao Wu, Yanyu Xiong, Luke Zettlemoyer, Dan Weld, Graham Neubig, Doug Downey, Wen-tau Yih, Pang Wei Koh, Hannaneh Hajishirzi' : '20 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">20 more authors</span> </div> <div class="periodical"> <em>Preprint (Under Review)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2411.14199" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/AkariAsai/OpenScholar" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://openscholar.allen.ai/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Scientific progress depends on researchers’ ability to synthesize the growing body of literature. Can large language models (LMs) assist scientists in this task? We introduce OpenScholar, a specialized retrieval-augmented LM that answers scientific queries by identifying relevant passages from 45 million open-access papers and synthesizing citation-backed responses. To evaluate OpenScholar, we develop ScholarQABench, the first large-scale multi-domain benchmark for literature search, comprising 2,967 expert-written queries and 208 long-form answers across computer science, physics, neuroscience, and biomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o hallucinates citations 78 to 90% of the time, OpenScholar achieves citation accuracy on par with human experts. OpenScholar’s datastore, retriever, and self-feedback inference loop also improves off-the-shelf LMs: for instance, OpenScholar-GPT4o improves GPT-4o’s correctness by 12%. In human evaluations, experts preferred OpenScholar-8B and OpenScholar-GPT4o responses over expert-written ones 51% and 70% of the time, respectively, compared to GPT4o’s 32%. We open-source all of our code, models, datastore, data and a public demo.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="shao2024scaling" class="col-sm-11"> <div class="title">Scaling Retrieval-Based Language Models with a Trillion-Token Datastore</div> <div class="author"> Rulin Shao ,  Jacqueline He ,  <em>Akari Asai</em> ,  Weijia Shi ,  Tim Dettmers , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Sewon Min, Luke Zettlemoyer, Pang Wei Koh' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2407.12854" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/RulinShao/retrieval-scaling" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://retrievalscaling.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Scaling laws with respect to the amount of training data and the number of parameters allow us to predict the cost-benefit trade-offs of pretraining language models (LMs) in different configurations. In this paper, we consider another dimension of scaling: the amount of data available at inference time. Specifically, we find that increasing the size of the datastore used by a retrieval-based LM monotonically improves language modeling and several downstream tasks without obvious saturation, such that a smaller model augmented with a large datastore outperforms a larger LM-only model on knowledge-intensive tasks. By plotting compute-optimal scaling curves with varied datastore, model, and pretraining data sizes, we show that using larger datastores can significantly improve model performance for the same training compute budget. We carry out our study by constructing a 1.4 trillion-token datastore named MassiveDS, which is the largest and the most diverse open-sourced datastore for retrieval-based LMs to date, and designing an efficient pipeline for studying datastore scaling in a computationally accessible manner. Finally, we analyze the effect of improving the retriever, datastore quality filtering, and other design choices on our observed scaling trends. Overall, our results show that datastore size should be considered as an integral part of LM efficiency and performance trade-offs.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="asai2024selfrag" class="col-sm-11"> <div class="title">Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection</div> <div class="author"> <em>Akari Asai</em> ,  Zeqiu Wu ,  Yizhong Wang ,  Avirup Sil ,  and  Hannaneh Hajishirzi </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations (ICLR; Oral, Top 1%)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2310.11511.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/AkariAsai/self-rag" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://selfrag.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM’s quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="asai2024retrieval" class="col-sm-11"> <div class="title">Reliable, Adaptable, and Attributable Language Models with Retrieval</div> <div class="author"> <em>Akari Asai</em> ,  Zexuan Zhong ,  Danqi Chen ,  Pang Wei Koh ,  Luke Zettlemoyer , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Hannaneh Hajishirzi, Wen-tau Yih' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2403.03187.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Parametric language models (LMs), which are trained on vast amounts of web data, exhibit remarkable flexibility and capability. However, they still face practical challenges such as hallucinations, difficulty in adapting to new data distributions, and a lack of verifiability. In this position paper, we advocate for retrieval-augmented LMs to replace parametric LMs as the next generation of LMs. By incorporating large-scale datastores during inference, retrieval-augmented LMs can be more reliable, adaptable, and attributable. Despite their potential, retrieval-augmented LMs have yet to be widely adopted due to several obstacles: specifically, current retrieval-augmented LMs struggle to leverage helpful text beyond knowledge-intensive tasks such as question answering, have limited interaction between retrieval and LM components, and lack the infrastructure for scaling. To address these, we propose a roadmap for developing general-purpose retrieval-augmented LMs. This involves a reconsideration of datastores and retrievers, the exploration of pipelines with improved retriever-LM interaction, and significant investment in infrastructure for efficient training and inference.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="mallen2022not" class="col-sm-11"> <div class="title">When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories</div> <div class="author"> Alex Mallen* ,  <em>Akari Asai*</em> ,  Victor Zhong ,  Rajarshi Das ,  Daniel Khashabi , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hannaneh Hajishirzi' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL; Oral, Best Video Paper Award – Most Viewed)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2212.10511.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/AlexTMallen/adaptive-retrieval" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the difficulty of encoding a wealth of world knowledge in their parameters. This paper aims to understand LMs’ strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments on two open-domain entity-centric QA datasets: PopQA, our new dataset with 14k questions about long-tail entities, and EntityQuestions, a widely used open-domain QA dataset. We find that LMs struggle with less popular factual knowledge, and that retrieval augmentation helps significantly in these cases. Scaling, on the other hand, mainly improves memorization of popular knowledge, and fails to appreciably improve memorization of factual knowledge in the tail. Based on those findings, we devise a new method for retrieval-augmentation that improves performance and reduces inference costs by only retrieving non-parametric memories when necessary.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <video src="https://aclanthology.org/2023.acl-long.546.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls></video> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div id="asai-etal-2023-task" class="col-sm-11"> <div class="title">Task-aware Retrieval with Instructions</div> <div class="author"> <em>Akari Asai</em> ,  Timo Schick ,  Patrick Lewis ,  Xilun Chen ,  Gautier Izacard , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Sebastian Riedel, Hannaneh Hajishirzi, Wen-tau Yih' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: ACL 2023 (Findings Spotlight)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2211.09260.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/facebookresearch/tart" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We study the problem of retrieval with instructions, where users of a retrieval system explicitly describe their intent along with their queries. We aim to develop a general-purpose task-aware retrieval system using multi-task instruction tuning, which can follow human-written instructions to find the best documents for a given query. We introduce the first large-scale collection of approximately 40 retrieval datasets with instructions, BERRI, and present TART, a multi-task retrieval system trained on BERRI with instructions. TART shows strong capabilities to adapt to a new retrieval task via instructions and advances the state of the art on two zero-shot retrieval benchmarks, BEIR and LOTTE, outperforming models up to three times larger. We further introduce a new evaluation setup, X^2-Retrieval to better reflect real-world scenarios, where diverse domains and tasks are pooled and a system needs to find documents aligning users’ intents. In this setup, TART significantly outperforms competitive baselines, further demonstrating the effectiveness of guiding retrieval with instructions.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <video src="https://aclanthology.org/2023.findings-acl.225.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls></video> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div id="asai-etal-2022-evidentiality" class="col-sm-11"> <div class="title">Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks</div> <div class="author"> <em>Akari Asai</em> ,  Matt Gardner ,  and  Hannaneh Hajishirzi </div> <div class="periodical"> <em>In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL; Oral)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2112.08688.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/AkariAsai/evidentiality_qa" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Retrieval-augmented generation models have shown state-of-the-art performance across many knowledge-intensive NLP tasks such as open-domain question answering and fact verification. These models are trained to generate a final output given retrieved passages that can be irrelevant to an input query, leading to learning spurious cues or memorization. This work introduces a method to incorporate \textitevidentiality of passages—whether a passage contains correct evidence to support the output—into training the generator. We introduce a multi-task learning framework to jointly generate the final output and predict the \textitevidentiality of each passage. Furthermore, we introduce a new task-agnostic method for obtaining high-quality \textitsilver evidentiality labels, addressing the issues of gold evidentiality labels being unavailable in most domains. Our experiments on five datasets across three knowledge-intensive tasks show that our new evidentiality-guided generator significantly outperforms its direct counterpart on all of them, and advances the state of the art on three of them. Our analysis shows that multi-task learning and silver evidentiality mining play key roles. Our code is available at \urlhttps://github.com/AkariAsai/evidentiality_qa</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <video src="https://aclanthology.org/2022.naacl-main.162.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls></video> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div id="asai-etal-2021-xor" class="col-sm-11"> <div class="title">XOR QA: Cross-lingual Open-Retrieval Question Answering</div> <div class="author"> <em>Akari Asai</em> ,  Jungo Kasai ,  Jonathan Clark ,  Kenton Lee ,  Eunsol Choi , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hannaneh Hajishirzi' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL; Oral)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2021.naacl-main.46.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/AkariAsai/XORQA" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Multilingual question answering tasks typically assume that answers exist in the same language as the question. Yet in practice, many languages face both information scarcity—where languages have few reference articles—and information asymmetry—where questions reference concepts from other cultures. This work extends open-retrieval question answering to a cross-lingual setting enabling questions from one language to be answered via answer content from another language. We construct a large-scale dataset built on 40K information-seeking questions across 7 diverse non-English languages that TyDi QA could not find same-language answers for. Based on this dataset, we introduce a task framework, called Cross-lingual Open-Retrieval Question Answering (XOR QA), that consists of three new tasks involving cross-lingual document retrieval from multilingual and English resources. We establish baselines with state-of-the-art machine translation systems and cross-lingual pretrained models. Experimental results suggest that XOR QA is a challenging task that will facilitate the development of novel techniques for multilingual question answering. Our data and code are available at https://nlp.cs.washington.edu/xorqa/.</p> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <video src="https://aclanthology.org/2021.naacl-main.46.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls></video> </figure> </div> </div> </div> </div> </li> <li> <div class="row"> <div id="Yamada2020LUKEDC" class="col-sm-11"> <div class="title">LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention</div> <div class="author"> Ikuya Yamada ,  <em>Akari Asai</em> ,  Hiroyuki Shindo ,  Hideaki Takeda ,  and  Yuji Matsumoto </div> <div class="periodical"> <em>In Conference on Empirical Methods in Natural Language Processing (EMNLP)</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2010.01057.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/studio-ousia/luke" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer. The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our model is trained using a new pretraining task based on the masked language model of BERT. The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at this https URL.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="asai2019learning" class="col-sm-11"> <div class="title">Learning to retrieve reasoning paths over wikipedia graph for question answering</div> <div class="author"> <em>Akari Asai</em> ,  Kazuma Hashimoto ,  Hannaneh Hajishirzi ,  Richard Socher ,  and  Caiming Xiong </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em> , 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/1911.10470.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://blog.salesforceairesearch.com/learning-to-retrieve-reasoning-paths-from-the-wikipedia-graph-for-question-answering/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Answering questions that require multi-hop reasoning at web-scale necessitates retrieving multiple evidence documents, one of which often has little lexical or semantic relationship to the question. This paper introduces a new graph-based recurrent retrieval approach that learns to retrieve reasoning paths over the Wikipedia graph to answer multi-hop open-domain questions. Our retriever model trains a recurrent neural network that learns to sequentially retrieve evidence paragraphs in the reasoning path by conditioning on the previously retrieved documents. Our reader model ranks the reasoning paths and extracts the answer span included in the best reasoning path. Experimental results show state-of-the-art results in three open-domain QA datasets, showcasing the effectiveness and robustness of our method. Notably, our method achieves significant improvement in HotpotQA, outperforming the previous best model by more than 14 points.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61%6B%61%72%69@%63%73.%77%61%73%68%69%6E%67%74%6F%6E.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=gqB4u_wAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/35584853" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/AkariAsai" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://twitter.com/AkariAsai" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Akari Asai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>
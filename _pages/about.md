---
layout: about
title: About
permalink: /
subtitle: Research Scientist @ <a href='https://allenai.org/'>Allen Institute for AI</a><br>Incoming Assistant Professor @ <a href='https://www.cs.cmu.edu/'>Carnegie Mellon University</a>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  # more_info: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

<!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](https://fontawesome.com/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

I am an incoming Assistant Professor at Carnegie Mellon University (Fall 2026-) [Language Technologies Institute](https://www.lti.cs.cmu.edu/), with an affiliate appointment in [the Machine Learning Department](https://ml.cmu.edu/) and a research scientist at [OLMo @ the Allen Institute for AI](https://allenai.org/) (2025-2026). 

**I am hiring 2-3 Ph.D. students at CMU in the 2025-2026 application cycle. Please check out [FAQ](https://akariasai.github.io/groups/) for more info.**

I've completed my Ph.D. in NLP at Paul G. Allen School of Computer Science & Engineering, University of Washington. I am fortunate to be advised by [Prof. Hannaneh Hajishirzi](https://homes.cs.washington.edu/~hannaneh/index.html). I was also spending time at [Meta AI Research](https://ai.meta.com/research/) as a visiting student researcher, under the supervision of [Dr. Wen-tau Yih](https://scottyih.org/). My Ph.D. pioneered [**Retrieval-Augmented LMs**](https://acl2023-retrieval-lm.github.io/), LMs that integrate large-scale text data via retrieval during inference ([thesis (PDF)](assets/pdf/akari_phd_dissertation.pdf), [vieo (youtube)](https://www.youtube.com/watch?v=qnWyU9zryao).)

Prior to joining UW, I obtained a B.E. in [Electrical Engineering and Computer Science](https://www.ee.t.u-tokyo.ac.jp/en/) from The University of Tokyo, Japan. 

**Current Research Focus:** 
My research focuses on natural language processing and machine learning, with a particular emphasis on large language models (LLMs). I'm interested in building LMs and agents that are more reliable, modular, and open, aimed at real-world impact in science, code, and global information access. 

- **Developing Augmented LMs**:
We design, train, and deploy augmented LMs and agents that collaborate with complementary modules—retrieval, tool use, multi-LM coordination, and more—moving beyond the limits of scaling a single monothilic model and introduce new training and inference algorithms for those methods.  Recent work includes advanced retrieval-augmented LMs such as [Self-RAG](https://arxiv.org/abs/2310.11511), and [DR Tulu](http://allenai-web/papers/drtulu), the first end-to-end open deep research agent for open-ended, long-form tasks trained with reinforcement learning with evolving rubrics. We also tackle system-level challenges for scalability and efficiency (e.g., [MassiveDS](https://arxiv.org/abs/2407.12854), [BPR](https://arxiv.org/abs/2106.00882)) and extend these capabilities to multimodal settings ([Pangea](https://arxiv.org/abs/2410.16153), [MM-RAG NeurIPS Competition](https://neurips.cc/virtual/2025/loc/san-diego/competition/127730)). 

- **Understanding and Mitigating Failure Modes of LMs**:
We systematically investigate where and why LMs fail, including hallucinations, copyright infringements, and unreliable reasoning, and design mechanisms to improve their reliability and safety. Projects such as [When Not to Trust LMs](https://arxiv.org/abs/2212.10511), copyright–utility trade-offs of LMs in [CopyBench](https://arxiv.org/abs/2407.07087), and analyses of capability–hallucination trade-offs in [Binary RAR](https://arxiv.org/abs/2510.17733) exemplify our efforts to make LMs more trustworthy and robust. 

- **Deploying Augmented LMs Ms in High-Impact Domains**:
We apply our methods to real-world challenges that demand factuality, transparency, and accessibility. Examples include AI for science ([OpenScholar](https://arxiv.org/abs/2411.14199), used by tens of thousands of scientists for literature synthesis), AI for code [CodeRAGBench](https://arxiv.org/abs/2406.14497), and AI for linguistic equity ([XORQA](https://arxiv.org/abs/2010.11856), [AfriQA](https://arxiv.org/abs/2305.06897), [CORA](https://arxiv.org/abs/2107.11976)), broadening global access to reliable information.




Selected recognitions include [MIT Technology Review 35 Innovators Under 35](https://www.technologyreview.com/innovators-under-35/2025/) (2025 Global & 2024 Japan), [Forbes 30 Under 30 Asia in Science 2025](https://www.forbes.com/30-under-30/2025/asia/healthcare-science), [EECS Rising Stars 2022](https://risingstars.utexas.edu/profiles/akari-asai), and the [IBM Global Ph.D. Fellows 2022-202](https://news.cs.washington.edu/2022/10/20/lost-in-translation-no-more-ibm-fellowship-winner-akari-asai-asks-and-answers-big-questions-in-nlp-to-expand-information-access-to-all/). Our work has been covered by [Forbes](https://www.forbes.com/councils/forbestechcouncil/2024/07/30/how-rag-powered-ai-applications-have-a-positive-impact-on-businesses/), [Nature News](https://www.nature.com/articles/d41586-025-02853-8), and [MIT Technology Review](https://www.technologyreview.com/2018/02/05/145813/100000-happy-moments/), and is used in libraries such as [Hugging Face](https://huggingface.co/docs/transformers/en/model_doc/luke), [LlamaIndex](https://docs.llamaindex.ai/en/stable/api_reference/packs/self_rag/), and [LangChain](https://blog.langchain.dev/agentic-rag-with-langgraph/). Most recently, the  [Ai2 OpenScholar Public Demo](https://openscholar.allen.ai/) has supported 50k researchers across scientific disciplines in synthesizing literature.


**Public office hours and application materials:** To help lower barriers to starting research, pursuing a Ph.D. in this field or job search, I host weekly office hours open to all every Friday. Feel free to sign up via (please sign up from [Google Calendar](https://calendar.app.google/3daW5UMPCNc7qJdQA)!). 

Inspired by many wonderful friends who have shared their own materials to promote equity and access, I’ve also made my past application materials available:

* Academic job application (2024): [[Research Statement]](assets/pdf/akariasai_2024_research.pdf), [[Teaching Statement]](assets/pdf/akariasai_2024_teaching.pdf), [[Diversity Statement]](assets/pdf/akariasai_2024_dei.pdf), [[Job Talk Slides]](assets/pdf/akari_job_talk_slides.pdf), [[Job Talk Video (defense recording)]](https://www.youtube.com/watch?v=qnWyU9zryao)
* EECS Rising Stars (2022): [[Research Statement]](assets/pdf/akari_eecs_rising_stars.pdf)
* PhD application (2018): [[SoP draft]](assets/pdf/akari_Sop_UW_Draft.pdf) (*Note: This is a near-final draft, as I don’t have access to the original version anymore! For examples of CS Statements of Purpose, I recommend checking out [cs-sop](https://cs-sop.notion.site/), which includes many CS SoP of previous applicants!*)